{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bceec8f5a546841a",
   "metadata": {},
   "source": [
    "# EM with Gaussian Mixture Models\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98002ac2a153da40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.166784Z",
     "start_time": "2025-11-10T17:59:31.829352Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de615059d7779057",
   "metadata": {},
   "source": [
    "## Color cycle\n",
    "Just for consistent visualization we pick the default matplotlib color cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c16044abe99201e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.174689Z",
     "start_time": "2025-11-10T17:59:32.172750Z"
    }
   },
   "outputs": [],
   "source": [
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ef7e4e221ca5d",
   "metadata": {},
   "source": [
    "## Expectation step\n",
    "In EM for GMM the expectation step consist in computing the responsibilities r_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9316cc4d4f2fc1c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.226198Z",
     "start_time": "2025-11-10T17:59:32.224027Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_responsibility(data, pi, mu, sigma):\n",
    "    n_classes = len(pi)\n",
    "\n",
    "    # Compute the numerator\n",
    "    unnormalized_resposibility = list()\n",
    "    for k in range(n_classes):\n",
    "        p_x_theta = multivariate_normal.pdf(data, mean=mu[k], cov=sigma[k])\n",
    "\n",
    "        r_ik_unnormalized = pi[k] * p_x_theta\n",
    "        unnormalized_resposibility.append(r_ik_unnormalized)\n",
    "\n",
    "    unnormalized_resposibility = np.stack(unnormalized_resposibility)\n",
    "\n",
    "    # Divide by the sum over all possible classes\n",
    "    r_ik = unnormalized_resposibility / unnormalized_resposibility.sum(axis=0)\n",
    "\n",
    "    return r_ik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec7df9fddd905c",
   "metadata": {},
   "source": [
    "## Maximization Step\n",
    "Now, given the responsibilities, the maximization step can be computed in closed form. Therefore we only need to compute the parameter update!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9e314db3d51899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.276878Z",
     "start_time": "2025-11-10T17:59:32.274636Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(data, r_i):\n",
    "    n_classes = len(r_i)\n",
    "    N = data.shape[0]\n",
    "\n",
    "    r_sum = r_i.sum(axis=1)\n",
    "\n",
    "    pi_new = list()\n",
    "    mu_new = list()\n",
    "    sigma_new = list()\n",
    "\n",
    "    for k in range(n_classes):\n",
    "        # Update class weights\n",
    "        pi_new_k = r_sum[k]/N\n",
    "\n",
    "        # Update mean\n",
    "        mu_new_k = r_i[k]@data/r_sum[k]\n",
    "\n",
    "        # Update covariance\n",
    "        delta_k = data - mu_new_k\n",
    "        sigma_new_k = delta_k.T @ np.diag(r_i[k]/r_sum[k]) @ delta_k\n",
    "\n",
    "        pi_new.append(pi_new_k)\n",
    "        mu_new.append(mu_new_k)\n",
    "        sigma_new.append(sigma_new_k)\n",
    "\n",
    "    return np.array(pi_new), np.stack(mu_new), np.stack(sigma_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083ef1a9c9cae4e",
   "metadata": {},
   "source": [
    "## Visualization functions\n",
    "Here we have some visualization functions.\n",
    "\n",
    "1. get_clusters identify the class with higher responsibility for each datapoint\n",
    "2. plot_dataset plots the raw dataset and the initial clusters\n",
    "3. plot_mixture is similar to plot data, but highlights the datapoints with colors related to the most important cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e3354d21ed67c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.332550Z",
     "start_time": "2025-11-10T17:59:32.327825Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_clusters(data, responsibility):\n",
    "    n_classes = len(responsibility)\n",
    "\n",
    "    # Associate datapoints to clusters, by selecting the highest responsibility\n",
    "    cluster_idx = np.argmax(responsibility, axis=0)\n",
    "\n",
    "    clusters = list()\n",
    "\n",
    "    # Split the data into cluster lists\n",
    "    for k in range(n_classes):\n",
    "        cluster_k = data[cluster_idx == k]\n",
    "        clusters.append(cluster_k)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def plot_dataset(data, mu, sigma):\n",
    "    n_clusters = len(mu)\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the raw data\n",
    "    plt.plot(data[:, 0], data[:, 1], 'g.')\n",
    "\n",
    "    # Plot the mixture model\n",
    "    for k in range(n_clusters):\n",
    "        plot_mixture(mu[k], sigma[k], default_colors[k])\n",
    "\n",
    "    # Set properly axis limits and aspect ratio\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mixture(mu, sigma, color, n_points=100):\n",
    "\n",
    "    # Find eigenvalues and eigenvectors of the covariance matrix\n",
    "    vals, vecs = np.linalg.eigh(sigma)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "\n",
    "    # Compute the rotation angle\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "\n",
    "    # Compute the scaling factor for each axis\n",
    "    chi = chi2.ppf(0.95, df=2)\n",
    "    width, height = 2 * np.sqrt(chi * vals)\n",
    "\n",
    "    # Generate the points of the ellipse and rotate them\n",
    "    t = np.linspace(0, 2*np.pi, n_points)\n",
    "    ellipse = np.column_stack([width/2 * np.cos(t), height/2 * np.sin(t)])\n",
    "    rot = np.array([[np.cos(np.radians(theta)), -np.sin(np.radians(theta))],\n",
    "                    [np.sin(np.radians(theta)), np.cos(np.radians(theta))]])\n",
    "    ellipse = ellipse @ rot.T + mu\n",
    "\n",
    "    # Plot the ellipse\n",
    "    plt.plot(ellipse[:,0], ellipse[:,1], color=color)[0]\n",
    "    plt.plot(mu[0], mu[1], 'x', color=color)\n",
    "\n",
    "\n",
    "def plot_cluster(clusters, mu, sigma):\n",
    "    plt.figure()\n",
    "\n",
    "    # plot the data separated in clusters and the mixtures\n",
    "    for k, cluster in enumerate(clusters):\n",
    "        plt.plot(cluster[:, 0], cluster[:, 1], '.', color=default_colors[k])\n",
    "        plot_mixture(mu[k], sigma[k], default_colors[k])\n",
    "\n",
    "    # Set properly axis limits and aspect ratio\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536743fe3b2d418a",
   "metadata": {},
   "source": [
    "## Main Loop\n",
    "Now we can run the EM algorithm following the three steps:\n",
    "1. Initialization\n",
    "2. Expectation\n",
    "3. Maximization\n",
    "\n",
    "Here we set a simplified convergence criterion: if the mean doesn't change much between two steps, terminate the algorithm. More advance criterion can be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829e6aff785b158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.379387Z",
     "start_time": "2025-11-10T17:59:32.377686Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195ae5682368a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.432742Z",
     "start_time": "2025-11-10T17:59:32.430256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Max iterations\n",
    "N = 20\n",
    "\n",
    "# Convergence threshold\n",
    "epsilon = 1e-3\n",
    "\n",
    "# Load dataset\n",
    "data = np.load(\"old_faithful_rescaled.npy\")\n",
    "xlim = [-2.0, 2.0]\n",
    "ylim = [-2.0, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced6a5d8c48be93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.479167Z",
     "start_time": "2025-11-10T17:59:32.477464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "pi_0 = 0.5\n",
    "mu_0 = np.array([1., 0])\n",
    "sigma_0 = 0.1*np.eye(2)\n",
    "\n",
    "pi_1 = 0.5\n",
    "mu_1 = np.array([-1., 0])\n",
    "sigma_1 = 0.1*np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffb5684ad8a1f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.527084Z",
     "start_time": "2025-11-10T17:59:32.525115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform everything in a single array\n",
    "pi =  np.array([pi_0, pi_1])\n",
    "mu = np.stack([mu_0, mu_1])\n",
    "sigma = np.stack([sigma_0, sigma_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d8b9b5e41295f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.623175Z",
     "start_time": "2025-11-10T17:59:32.572996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot dataset\n",
    "plot_dataset(data, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d914bbb5bd1c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T17:59:32.896575Z",
     "start_time": "2025-11-10T17:59:32.632875Z"
    }
   },
   "outputs": [],
   "source": [
    "# EM loop\n",
    "for it in range(N):\n",
    "    old_mu = mu.copy()\n",
    "    old_sigma = sigma.copy()\n",
    "    old_pi = pi.copy()\n",
    "\n",
    "    # Expectation\n",
    "    responsibility = compute_responsibility(data, pi, mu, sigma)\n",
    "\n",
    "    # Maximization\n",
    "    pi, mu, sigma = update_parameters(data, responsibility)\n",
    "\n",
    "    # Find the clusters\n",
    "    clusters = get_clusters(data, responsibility)\n",
    "\n",
    "    # Plot results\n",
    "    plot_cluster(clusters, mu, sigma)\n",
    "\n",
    "    # Check for convergence (simplified)\n",
    "    if np.linalg.norm(old_mu - mu) < epsilon:\n",
    "        print('Algorithm converged!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dbb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
